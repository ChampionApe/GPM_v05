{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file_gams_py_gdb0.gdx is still active and was not deleted.\n"
     ]
    }
   ],
   "source": [
    "clean_up=True # removes gams-related files in work-folder if true\n",
    "%run StdPackages.ipynb\n",
    "os.chdir(directory['py'])\n",
    "import abatement, techdata_to_tree, sys, ShockFunction\n",
    "os.chdir(directory['curr'])\n",
    "def flatten_list(list_):\n",
    "    return [item for sublist in list_ for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Set up tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read data:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = \"techdata_dors_3_overlap.xlsx\" # file\n",
    "inputoth  = 'Othdata_dors_3.xlsx'\n",
    "output = techdata_to_tree.load_techcats(pd.read_excel(directory['data'] + \"/\" + inputfile, sheet_name=[\"inputdisp\", \"endofpipe\", \"inputprices\"]))\n",
    "modules = [\"ID\", \"EOP\"] # modules to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Set up trees:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts = {m: nesting_tree.nesting_tree(name=m) for m in modules}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1: Input displacing tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"ID\"].add_tree(output[\"ID\"][\"upper_categories\"], tree_name = 'ID_EC', **{\"type_f\":\"CES_norm\"}) # E to C\n",
    "nts[\"ID\"].add_tree(output[\"ID\"][\"components\"], tree_name = \"ID_CU\", **{\"type_f\":\"MNL\"}) # C to U\n",
    "nts[\"ID\"].add_tree(output[\"ID\"][\"techs\"], tree_name=\"ID_TU\", **{'type_io': 'output', 'type_f': 'CET_norm'}) # U to T\n",
    "nts[\"ID\"].add_tree(output[\"ID\"][\"techs_inputs\"], tree_name=\"ID_TX\") # T to inputs X\n",
    "nts[\"ID\"].add_tree(output[\"ID\"][\"basetechs\"], tree_name=\"ID_BU\", **{\"type_io\":\"output\", \"type_f\":\"linear_out\"}) # baseline technologies\n",
    "nts[\"ID\"].add_tree(output[\"ID\"][\"basetech_inputs\"], tree_name=\"ID_BX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2: End of pipe tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"EOP\"].add_tree(output[\"EOP\"][\"components\"], tree_name = \"EOP_CU\", **{\"type_f\":\"MNL\"}) # C to U\n",
    "nts[\"EOP\"].add_tree(output[\"EOP\"][\"techs\"], tree_name=\"EOP_TU\", **{'type_io': 'output', 'type_f': 'CET_norm'}) # T to U \n",
    "nts[\"EOP\"].add_tree(output[\"EOP\"][\"techs_inputs\"], tree_name=\"EOP_TX\") # T to inputs X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3: Trees related to final goods and emissions account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read in tree and data from xlsx:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts['ID'].add_tree(directory['data']+'\\\\'+inputoth,tree_name='ID_Y',**{'sheet':'Y'})\n",
    "# DataBase.GPM_database.merge_dbs(nts['ID'].trees['ID_Y'].database,\n",
    "#                                 excel2py.xl2PM.pm_from_workbook(directory['data']+'\\\\'+inputoth,{'Y': 'vars', 'M': 'vars','M_sets': 'sets'}), 'first')\n",
    "\n",
    "\n",
    "DataBase.GPM_database.merge_dbs(nts['ID'].trees['ID_Y'].database,\n",
    "                                excel2py.xl2PM.pm_from_workbook(directory['data']+'\\\\'+inputoth,{'Y': 'vars'}), 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Add new Q2P:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['ID']['Q2P'] = output['ID']['Q2P'].append(excel2py.xl2PM.pm_from_workbook(directory['data']+'\\\\'+inputoth,{'Q2P': 'maps'}).database['Q2P'].vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#midlertidigt fix. run_all metoden laver nodes som ikke er i træet om til nan her i phi\n",
    "#phi = nts[\"ID\"].trees[\"ID_Y\"].database[\"phi\"].vals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3: Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Give modules local namespaces:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_sets = ('inp','out','int','wT','map_all','kno_out','kno_inp')\n",
    "for module in modules:\n",
    "    namespace = {k: module + '_' + k for k in standard_sets}\n",
    "    nts[module].run_all(**namespace)\n",
    "    #Also replaces keys with module-specific names, i.e. changes 'inp' to 'ID_inp' in the attributes/keys.\n",
    "    for std_set in standard_sets:\n",
    "        if hasattr(nts[module], std_set):\n",
    "            setattr(nts[module], module + \"_\" + std_set, getattr(nts[module], std_set))\n",
    "            delattr(nts[module], std_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midlertidigt fix af phi der giver naner på alt andet end inp3\n",
    "DataBase.GPM_database.merge_dbs(nts['ID'].database,\n",
    "                                excel2py.xl2PM.pm_from_workbook(directory['data']+'\\\\'+inputoth,{'M': 'vars','M_sets': 'sets'}), 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Additional objects derived from the catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Load*: \n",
    "- $\\mu$ parameters deducted from the catalog directly, \n",
    "- current applications according to the potential split (latter used for starting values),\n",
    "- Q2P\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Initialize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = abatement.abate(nt=nts['ID'],tech=output,work_folder=directory['work'],**{'data_folder':directory['gams'],'name': 'atest'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.add_aliases([('n','nnnn'),('n','nnnnn')])\n",
    "gm.model.database.update_all_sets(clean_up=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.write_and_run(kwargs_init={'check_variables':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_star = DataBase.GPM_database(**{'name': 'db_star'})\n",
    "sigma_star = gm.get(\"sigma\").copy()\n",
    "eta_star = gm.get(\"eta\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_star[:] = -3\n",
    "sigma_star[gm.get(\"kno_ID_CU\")] = 0.4\n",
    "sigma_star[gm.get(\"kno_no_ID_BX\")] = 0.5\n",
    "sigma_star[\"Y\"] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_star[\"sigma\"] = sigma_star\n",
    "db_star[\"eta\"] = eta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='v0'\n",
    "gm.write_and_run(name=name, add_checkpoint=name)\n",
    "gm.checkpoints['v1'] = gm.model_instances[name].ws.add_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelstat': 16.0, 'Solvestat': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.model_instances[name].solve_sneakily(db_star=db_star,from_cp = True, cp_init = gm.checkpoints[name], options_run={'checkpoint': gm.checkpoints['v1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.model.database.merge_dbs(gm.model.database,gm.model_instances['v0'].out_db,'second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_star = DataBase.GPM_database(**{'name': 'db_star'})\n",
    "sigma_star = gm.get(\"sigma\").copy()\n",
    "sigma_star[gm.get(\"kno_ID_CU\")] = 4\n",
    "db_star[\"sigma\"] = sigma_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='v2'\n",
    "gm.write_and_run(name=name, add_checkpoint=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.checkpoints['v3'] = gm.model_instances[name].ws.add_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelstat': 16.0, 'Solvestat': 1.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.model_instances[name].solve_sneakily(db_star=db_star,from_cp = True, cp_init = gm.checkpoints[name], options_run={'checkpoint': gm.checkpoints['v3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = Production.pr_static(nt=nt,work_folder=directory['work'],**{'data_folder':gams_folder,'name':'A1'})\n",
    "gm.write_and_run(kwargs_init={'check_variables':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = {\"ID\":DataBase.GPM_database(), \"EOP\":DataBase.GPM_database()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Define auxiliary sets:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'ID'\n",
    "db,nt = nts[m].database, nts[m]\n",
    "n,nn,nnn = nts[m].n, nts[m].nn, nts[m].nnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Subsets for different types of nests:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[m+'_t'] = pd.Index(output[m]['techs'].keys(),name=n) # technologies\n",
    "db[m+'_t_all'] = pd.Index(output[m]['basetechs'].keys(),name=n).union(db.get(m+'_t')) # technologies including baselines\n",
    "db[m+'_c'] = pd.Index(output[m]['components'].keys(), name = n) # subset of components\n",
    "db[m+'_e'] = pd.Index(output[m]['upper_categories'].keys(), name = n) # energy services\n",
    "db[m+'_e_all'] = pd.Index(['Y'],name=n).union(db.get(m+'_e')) # energy services nest including other inputs (Y)\n",
    "db[m+'_u_all'] = pd.Index([x for y in output[m]['components'].values() for x in y], name = n) # all technology goods\n",
    "db[m+'_u'] = db.get(m+'_u_all').difference(pd.Index([x for y in output[m]['basetechs'].values() for x in y], name = n)) # technology goods, not baseline firms\n",
    "db['ai'] = output['ID']['Q2P'].levels[1].rename(n) # subset of aggregate goods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mappings (do we want to store these for later?):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2t = db.get(m+'_map_all')[(db.get(m+'_map_all').get_level_values(n).isin(db.get(m+'_inp'))) & \n",
    "                           (db.get(m+'_map_all').get_level_values(nn).isin(db.get(m+'_t_all')))]\n",
    "u2t = db.get(m+'_map_all')[(db.get(m+'_map_all').get_level_values(n).isin(db.get(m+'_u_all'))) &\n",
    "                           (db.get(m+'_map_all').get_level_values(nn).isin(db.get(m+'_t_all')))]\n",
    "u2c = db.get(m+'_map_all')[(db.get(m+'_map_all').get_level_values(n).isin(db.get(m+'_u_all'))) & \n",
    "                           (db.get(m+'_map_all').get_level_values(nn).isin(db.get(m+'_c')))]\n",
    "c2e = db.get(m+'_map_all')[(db.get(m+'_map_all').get_level_values(n).isin(db.get(m+'_c'))) & \n",
    "                           (db.get(m+'_map_all').get_level_values(nn).isin(db.get(m+'_e_all')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*When identifying the level of current coverage for a technology type, we map from energy service to u:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[m+'_e2u'] = DataBase_wheels.appmap(u2c,DataBase_wheels.map_from_mi(c2e,n,nn),nn).swaplevel(0,1).set_names([n,nn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Energy service type to technology type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[m+'_e2t'] = DataBase_wheels.appmap(db.get(m+'_e2u'),DataBase_wheels.map_from_mi(u2t,n,nn),nn).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Energyservice 2 aggregate input type 2 inidividual input type:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('CO2',           'K'),\n",
       "            ('CO2', 'electricity'),\n",
       "            ('CO2',        'inp3'),\n",
       "            ('CO2',         'oil')],\n",
       "           names=['z', 'n'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.MultiIndex.from_product([pd.Index(['CO2'],name='z'),db.get('ai')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2ai = output['ID']['Q2P'] # individual inputs 2 aggregate inputs\n",
    "t2i2ai = DataBase_wheels.mi.add_ndmi(i2t.swaplevel(0,1).set_names([n,nn]),i2ai.set_names([nn,nnn])) # technology 2 individual 2 aggregate input\n",
    "db[m+'_e2ai2i'] = DataBase_wheels.appmap(t2i2ai,DataBase_wheels.map_from_mi(db.get(m+'_e2t'),nn,n),n).swaplevel(1,2).set_names([n,nn,nnn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these mappings:\n",
    "* Define qSumU[n,nn] as the production by technology (n) of energy service (nn). This should be computed as: (NOTE: We define qsumU over n=e and nn = t instead):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{qSumU[n,nn]} = \\text{sum(nnn\\$(e2t[nn,n] and e2u[nn,nnn]), qD[nnn])}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* Define the output share os[n,nn] as the share of output that technology $n$ produces of energy-service type $nn$. This should be defined as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{os[n,nn]} = \\text{sum(nnn\\$(e2u[nn,nnn] and u2t[nnn,n]), qD[nnn]) / qD[n]}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* Define variable qSumX[n,nn] defined as the use of aggregate input type $nn\\in (electricity,oil,inp3,K)$ used to produce energy service $n$. This is defined as:\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\text{qSumX[n,nn]} = \\text{sum([nnn,nnnn]\\$(e2ai2i[n,nn,nnn] and e2t[n,nnnn] and i2t[nnn,nnnn]), qD[nnn] * os[nnnn,n])}\n",
    "\\end{align}$$\n",
    "* Here e2ai2i identifies the relevant quantities $qD[i]$ that are tied to relevant aggregate type of input, $e2t[e,t]$ identifies the correct output-share $os[t,e]$, and $i2t[i,t]$ ensures that only the relevant $i,t$ combinations are summed over.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond these book keeping variables, we define a number of variables used in calibration:\n",
    "\n",
    "* Define $currapp[n,nn]$ as the current share of coverage of a technology $n$ of energy-service $nn$. This is simply defined as (maybe we don't need to define the qSumU variable?)\n",
    "\n",
    "$$\\begin{align}\n",
    "    curapp[n,nn] = qSumU[n,nn] / qD[nn].\n",
    "\\end{align}$$\n",
    "* Define the level of application ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
