{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0: Load packages, scripts etc.\n",
    "- 1: Construct trees. Uses the technology data stored in an .xlsx-file to construct dictionaries and other objects that fully characterize the production tree. These are then combined to an actual tree object using the nestingtree.nestingtree class.\n",
    "- 2: Adding parameters to the database. Only some of the share-parameters etc. can be deduced directly from technology data. The rest of these as well as starting values for endogenous and exogenous variables must be collected in a database.\n",
    "- 3: The model. Uses the tree object as well as the prepared database to construct a model using the *gmspython* class and its childclass *abate*.\n",
    "The script ends by exporting the model as a pickle to be loaded in the calibration script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file_gams_py_gdb0.gdx is still active and was not deleted.\n"
     ]
    }
   ],
   "source": [
    "clean_up=True # removes gams-related files in work-folder if true\n",
    "%run StdPackages.ipynb\n",
    "os.chdir(py['main'])\n",
    "import abatement, techdata_to_tree, sys, ShockFunction\n",
    "os.chdir(curr)\n",
    "data_folder = os.getcwd()+'\\\\Data'\n",
    "gams_folder = data_folder + \"\\\\..\\\\gamsmodels\\\\Main\"\n",
    "#Functions\n",
    "def flatten_list(list_):\n",
    "    return [item for sublist in list_ for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1: Construct trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load technology data.\n",
    "This runs the script in located in the file *techdata_to_tree.py*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = \"techdata_new2.xlsx\"\n",
    "output = techdata_to_tree.load_techcats(pd.read_excel(data_folder + \"/\" + inputfile, sheet_name=[\"inputdisp\", \"endofpipe\", \"inputprices\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output of the code is a dictionary with three keys, referring to the two modules + a list of inputprices stored in the xlsx-file as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ID', 'inputprices', 'EOP'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two different modules correspond to the two types of technology catalogs that the model can handle.\\\n",
    "*Input-displacing* (ID) and *End of pipe* (EOP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [\"ID\", \"EOP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID contains a dictionary related to input-displacing technologies, EOP does so for end of pipe (we use this naming convention throughout).\\\n",
    "They contain the following keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of ID:  dict_keys(['techs_inputs', 'techs', 'components', 'upper_categories', 'mu', 'Q2P', 'unit_costs', 'current_coverages', 'coverage_potentials', 'basetechs', 'basetech_inputs']) \n",
      "\n",
      "Keys of EOP:  dict_keys(['techs_inputs', 'techs', 'components', 'upper_categories', 'mu', 'Q2P', 'unit_costs', 'current_coverages', 'coverage_potentials']) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for module in modules:\n",
    "    print(\"Keys of \" + module + \": \", output[module].keys(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, \"techs\" shows, for each technology, which technology good it produces, e.g. for input-displacing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID_1': ['U_ID_1_1', 'U_ID_1_2', 'U_ID_1_3'],\n",
       " 'ID_2': ['U_ID_2_1', 'U_ID_2_2', 'U_ID_2_3'],\n",
       " 'ID_3': ['U_ID_3_1', 'U_ID_3_2'],\n",
       " 'ID_4': ['U_ID_4_1', 'U_ID_4_2', 'U_ID_4_3'],\n",
       " 'ID_5': ['U_ID_5_1', 'U_ID_5_2']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"ID\"][\"techs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And \"upper_categories\" shows the mapping between energy services (E) and their respective components (C) for ID.\\\n",
    "All of the trees in the `output` object are dictionaries where the keys are nodes in the tree and the values are lists of connected branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EL': ['C_EL_1', 'C_EL_2', 'C_EL_3', 'C_EL_4', 'C_EL_5', 'C0_EL'],\n",
       " 'EH': ['C_EH_1', 'C_EH_2', 'C_EH_3', 'C0_EH'],\n",
       " 'ER': ['C_ER_1', 'C_ER_2', 'C0_ER']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"ID\"][\"upper_categories\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the mapping between emission types M ($CO_2$, $SO_2$ etc.) and the components C.\\\n",
    "Note importantly that this mapping does not constitute an actual part of the tree, because components are the outputs of the EOP sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CO2': ['C_CO2_1'],\n",
       " 'SO2': ['C_SO2_1', 'C_SO2_2', 'C_SO2_3'],\n",
       " 'NOX': ['C_NOX_1', 'C_NOX_2', 'C_NOX_3', 'C_NOX_4']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"EOP\"][\"upper_categories\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize nesting tree, call it \"Abatement\"\n",
    "The construction of the production tree starts with an initialization of the *nesting_tree* class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts = {\"ID\":nesting_tree.nesting_tree(name=\"ID\"), \"EOP\":nesting_tree.nesting_tree(name=\"EOP\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"trees\" attribute starts off empty, reflecting that no (sub)trees have been added yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts[\"ID\"].trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cells add each of the subtrees to the tree-object, \"nt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, input-displacing subtrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upper part, connecting energy services to components (this is an input-tree, so we do not supply additional keyword arguments).\\\n",
    "Again, we use the naming convention that a prefix reflects whether the tree is related to input-displacement (ID) or end of pipe (EOP).\n",
    "The prefix is followed by an underscore and then letters reflecting which elements in the tree are connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first tree connects energy services (E) to components (C), related to input-displacing technologies (ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"ID\"].add_tree(output[\"ID\"][\"upper_categories\"], tree_name = 'ID_EC', **{\"type_f\":\"CES_norm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to the next tree, lets print some information from this tree.\\\n",
    "First, we see that the tree has been added to the list of trees in the \"aggregate\" tree, nt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID_EC': <nesting_trees.nt at 0x26874843388>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts[\"ID\"].trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, information about the tree is automatically added when the tree is added, e.g. the \"type_f\" attribute states that the functional form in this subtree is constant elasticity of substitution (CES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ID_EC',\n",
       " 'tree': {'EL': ['C_EL_1', 'C_EL_2', 'C_EL_3', 'C_EL_4', 'C_EL_5', 'C0_EL'],\n",
       "  'EH': ['C_EH_1', 'C_EH_2', 'C_EH_3', 'C0_EH'],\n",
       "  'ER': ['C_ER_1', 'C_ER_2', 'C0_ER']},\n",
       " 'type_io': 'input',\n",
       " 'version': 'std',\n",
       " 'n': 'n',\n",
       " 'nn': 'nn',\n",
       " 'nnn': 'nnn',\n",
       " 'nnnn': 'nnnn',\n",
       " 'nnnnn': 'nnnnn',\n",
       " 'map_': 'map_ID_EC',\n",
       " 'kno': 'kno_ID_EC',\n",
       " 'bra': 'bra_ID_EC',\n",
       " 'inp': 'inp_ID_EC',\n",
       " 'out': 'out_ID_EC',\n",
       " 'temp_namespace': None,\n",
       " 'type_f': 'CES_norm',\n",
       " 'database': <DataBase.GPM_database at 0x2687481a148>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts[\"ID\"].trees[\"ID_EC\"].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, even though the namespace includes e.g. \"map_\":\"map_ID_EC\", the database of the tree still does not contain this mapping. This requires running the run() method.\\\n",
    "Instead of doing that for each tree individually, we instead add all trees and call the run_all() methods which also calls the run() on each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add the middle part, connecting components C to their technology goods U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"ID\"].add_tree(output[\"ID\"][\"components\"], tree_name = \"ID_CU\", **{\"type_f\":\"MNL\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two remaining parts are the bottom ones. \\\n",
    "First, the one that connects technologies to their outputs (technology goods). That these are outputs is specified explicitly by using the `type_io` keyword.\\\n",
    "Second, the one that connects technologies to their inputs (non-capital inputs X, and capital K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"ID\"].add_tree(output[\"ID\"][\"techs\"], tree_name=\"ID_TU\", **{'type_io': 'output', 'type_f': 'CET_norm'})\n",
    "nts[\"ID\"].add_tree(output[\"ID\"][\"techs_inputs\"], tree_name=\"ID_TX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline components and technology goods, and their respective sets of inputs are also part of the aggregate tree. We distinguish between those with their own inputs (these baseline technologies are the ones that come from knowing which energy mix a (set of) technologies replaces. The remaining baseline technology goods (and all baseline components by construction) are outputs of the \"IO technology\". This IO technology in turn draws on all inputs from the economy. This is the one we calibrate to make sure we replicate IO data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"ID\"].add_tree(output[\"ID\"][\"basetechs\"], tree_name=\"ID_BU\", **{\"type_io\":\"output\", \"type_f\":\"CET_norm\"})\n",
    "nts[\"ID\"].add_tree(output[\"ID\"][\"basetech_inputs\"], tree_name=\"ID_IOX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if output[\"ID\"][\"baseline_U_inputs\"]:\n",
    "#     nts[\"ID\"].add_tree(output[\"ID\"][\"baseline_U_inputs\"], tree_name=\"ID_UbaseX\")\n",
    "# else:\n",
    "#     print(\"No replacing baseline technology goods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we add the end of pipe subtrees.\n",
    "First, the one connecting components (which are the final product in the end-of-pipe tree) to the technology goods from which they are created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"EOP\"].add_tree(output[\"EOP\"][\"components\"], tree_name = \"EOP_CU\", **{\"type_f\":\"MNL\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the bottom part. This consists of technologies and their outputs and inputs respectively, similarly to with input-displacing technologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"EOP\"].add_tree(output[\"EOP\"][\"techs\"], tree_name=\"EOP_TU\", **{'type_io': 'output', 'type_f': 'CET_norm'})\n",
    "nts[\"EOP\"].add_tree(output[\"EOP\"][\"techs_inputs\"], tree_name=\"EOP_TX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trees related to final goods: One taking energy services and remaining inputs to produce a composite good Y, and one splitting Y into sX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_inputs = list(output[\"ID\"][\"upper_categories\"].keys())\n",
    "Y_outputs = [\"Y_out_\" + c for c in list(output[\"inputprices\"].keys()[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2P_addition = []\n",
    "for inp in list(output[\"inputprices\"].index[:-1]) + [\"K\"]:\n",
    "    Y_inputs += [\"Y_in_\" + inp]\n",
    "    Q2P_addition.append((\"Y_in_\" + inp, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"ID\"][\"Q2P\"] = output[\"ID\"][\"Q2P\"].append(pd.MultiIndex.from_tuples(Q2P_addition, names=[\"n\", \"nn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Share parameters are simply 1/N on both the input and output side\n",
    "for inp in Y_inputs:\n",
    "    output[\"ID\"][\"mu\"][(inp, \"Y\")] = 1/len(Y_inputs)\n",
    "for out in Y_outputs:\n",
    "    output[\"ID\"][\"mu\"][(out, \"Y\")] = 1/len(Y_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts[\"ID\"].add_tree({\"Y\":Y_inputs}, tree_name=\"ID_Y_in\")\n",
    "nts[\"ID\"].add_tree({\"Y\":Y_outputs}, tree_name=\"ID_Y_out\", **{'type_io': 'output', 'type_f': 'CET'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, all trees have been added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID_EC': <nesting_trees.nt object at 0x0000026874843388>, 'ID_CU': <nesting_trees.nt object at 0x0000026874B06A08>, 'ID_TU': <nesting_trees.nt object at 0x0000026874AD15C8>, 'ID_TX': <nesting_trees.nt object at 0x0000026874AD1608>, 'ID_BU': <nesting_trees.nt object at 0x0000026874B25C48>, 'ID_IOX': <nesting_trees.nt object at 0x0000026874B25BC8>, 'ID_Y_in': <nesting_trees.nt object at 0x0000026874B15508>, 'ID_Y_out': <nesting_trees.nt object at 0x0000026874B158C8>} \n",
      " {'EOP_CU': <nesting_trees.nt object at 0x000002687483A248>, 'EOP_TU': <nesting_trees.nt object at 0x0000026874B14AC8>, 'EOP_TX': <nesting_trees.nt object at 0x0000026874B14BC8>}\n"
     ]
    }
   ],
   "source": [
    "print(nts[\"ID\"].trees, \"\\n\", nts[\"EOP\"].trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next step is to use the method `run_all`. This runs through a number of steps, where it sets up sets/subsets/mappings identifying which elements e.g. are inputs, intermediate goods, and outputs in the aggregate tree, i.e. the combination of the subtrees we just added. *Tutorial_nesting_tree* includes a brief review of these.\\\n",
    "There are still some of the objects in `output` that we have not used. We will return to these later as they become relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ID',\n",
       " 'version': 'std',\n",
       " 'trees': {'ID_EC': <nesting_trees.nt at 0x26874843388>,\n",
       "  'ID_CU': <nesting_trees.nt at 0x26874b06a08>,\n",
       "  'ID_TU': <nesting_trees.nt at 0x26874ad15c8>,\n",
       "  'ID_TX': <nesting_trees.nt at 0x26874ad1608>,\n",
       "  'ID_BU': <nesting_trees.nt at 0x26874b25c48>,\n",
       "  'ID_IOX': <nesting_trees.nt at 0x26874b25bc8>,\n",
       "  'ID_Y_in': <nesting_trees.nt at 0x26874b15508>,\n",
       "  'ID_Y_out': <nesting_trees.nt at 0x26874b158c8>},\n",
       " 'database': <DataBase.GPM_database at 0x26874843ec8>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts[\"ID\"].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_sets = ('inp','out','int','wT','map_all','kno_out','kno_inp')\n",
    "for module in modules:\n",
    "    namespace = {k: module + '_' + k for k in standard_sets}\n",
    "    nts[module].run_all(**namespace)\n",
    "    #Also replaces keys with module-specific names, i.e. changes 'inp' to 'ID_inp' in the attributes/keys.\n",
    "    for std_set in standard_sets:\n",
    "        if hasattr(nts[module], std_set):\n",
    "            setattr(nts[module], module + \"_\" + std_set, getattr(nts[module], std_set))\n",
    "            delattr(nts[module], std_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This constructs the aggregate tree. \\\n",
    "For a few highlights, let's check:\n",
    "1. The outputs of the aggregate tree (aggregate simply refers to the combination of all the individual (sub)trees\\\n",
    "This includes energy services (from ID) and components (from EOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y_out_inp3', 'Y_out_oil', 'Y_out_inp4', 'Y_out_electricity', 'Y_out_inp5']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nts[\"ID\"].database.series[\"ID_out\"].vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The outputs of a particular tree, say EOP_TU. Note that in this particular case, the reported list is empty. This is because an 'output' refers to whether it is an output of the aggregate tree and not just this particular one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EOP_t4', 'EOP_t5', 'EOP_t3', 'EOP_t2', 'EOP_t1']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nts[\"EOP\"].trees[\"EOP_TU\"].database.series[\"out_EOP_TU\"].vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Likewise, we can check the inputs of EOP_TU\\\n",
    "This reports that the Us are inputs, which they really are not. This is not a problem, because the tree is constructed in the correct way. But not that U's are not inputs. Not of the aggregate tree (in which Us are intermediates), but not in the TU-tree either, since here, they are outputs (they are produced by technologies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['U_EOP_t2_1', 'U_EOP_t2_3', 'U_EOP_t2_2', 'U_EOP_t1_2', 'U_EOP_t5_1',\n",
       "       'U_EOP_t1_1', 'U_EOP_t5_2', 'U_EOP_t4_2', 'U_EOP_t3_1', 'U_EOP_t4_1'],\n",
       "      dtype='object', name='n')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts[\"EOP\"].trees[\"EOP_TU\"].database.series[\"inp_EOP_TU\"].vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets print the objects that the `nt` class instance contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ID',\n",
       " 'version': 'std',\n",
       " 'trees': {'ID_EC': <nesting_trees.nt at 0x26874843388>,\n",
       "  'ID_CU': <nesting_trees.nt at 0x26874b06a08>,\n",
       "  'ID_TU': <nesting_trees.nt at 0x26874ad15c8>,\n",
       "  'ID_TX': <nesting_trees.nt at 0x26874ad1608>,\n",
       "  'ID_BU': <nesting_trees.nt at 0x26874b25c48>,\n",
       "  'ID_IOX': <nesting_trees.nt at 0x26874b25bc8>,\n",
       "  'ID_Y_in': <nesting_trees.nt at 0x26874b15508>,\n",
       "  'ID_Y_out': <nesting_trees.nt at 0x26874b158c8>},\n",
       " 'database': <DataBase.GPM_database at 0x26874843ec8>,\n",
       " 'n': 'n',\n",
       " 'nn': 'nn',\n",
       " 'nnn': 'nnn',\n",
       " 'nnnn': 'nnnn',\n",
       " 'nnnnn': 'nnnnn',\n",
       " 'fg': 'fg',\n",
       " 'prune_trees': {'OnlyQ', 'bra', 'inp', 'kno', 'out'},\n",
       " 'ID_inp': 'ID_inp',\n",
       " 'ID_out': 'ID_out',\n",
       " 'ID_int': 'ID_int',\n",
       " 'ID_wT': 'ID_wT',\n",
       " 'ID_map_all': 'ID_map_all',\n",
       " 'ID_kno_out': 'ID_kno_out',\n",
       " 'ID_kno_inp': 'ID_kno_inp'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts[\"ID\"].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5: Construct some sets needed before calculating starting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiindex_series(idx_level_names, idx_name=None, series_name=None):\n",
    "    if idx_name is None and series_name is not None:\n",
    "        idx_name = series_name\n",
    "    elif idx_name is not None and series_name is None:\n",
    "        series_name = idx_name\n",
    "    elif idx_name is None and series_name is None:\n",
    "        raise Exception(\"Supply either index name or series name\")\n",
    "    idx = pd.MultiIndex(levels=[[]]*len(idx_level_names), codes=[[]]*len(idx_level_names), names=idx_level_names)\n",
    "    ser = pd.Series(index=idx, dtype=float)\n",
    "    ser.rename(series_name, inplace=True)\n",
    "    #ser.index.name = idx_name\n",
    "    return ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key_from_value(d, value):\n",
    "    assert isinstance(d, dict)\n",
    "    out = []\n",
    "    for (k, v) in d.items():\n",
    "        if value in v:\n",
    "            out.append(k)\n",
    "    if len(out) == 1:\n",
    "        return out[0]\n",
    "    else:\n",
    "        raise Exception(\"Value exists in multiple keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_true_input(inp, Q2P):\n",
    "    true = list(Q2P[Q2P.get_level_values(0).isin([inp])].get_level_values(1))[0]\n",
    "    return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_E_in_name(name, energy_services):\n",
    "    found_e = [e for e in energy_services if e in name]\n",
    "    if len(found_e) != 1:\n",
    "        raise Exception(\"found zero or more than 1 E\")\n",
    "    else:\n",
    "        return found_e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_X_in_name(name, inputs):\n",
    "    found = [X for X in inputs if X in name]\n",
    "    if len(found) != 1:\n",
    "        raise Exception(\"found zero or more than 1 E\")\n",
    "    else:\n",
    "        return found[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumX. The sum of energy use for baseline technologies (IO_tech + replacing baselines)\n",
    "\n",
    "# sumXinEaggs = pd.Series([], index=)\n",
    "\n",
    "\n",
    "sumXinE2baselineinputs = multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"map_sumXinE2baselineinputs\")\n",
    "sumXinE2E = multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"map_sumXinE2E\")\n",
    "sumXinE2X = multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"map_sumXinE2X\")\n",
    "\n",
    "for basetech in output[\"ID\"][\"basetech_inputs\"]:\n",
    "    e = find_E_in_name(basetech, list(output[\"ID\"][\"upper_categories\"].keys()))\n",
    "    for x in output[\"ID\"][\"basetech_inputs\"][basetech]:\n",
    "        inp = find_true_input(x, output[\"ID\"][\"Q2P\"])\n",
    "        sumXinE2baselineinputs[(\"sum_\" + e + \"_\" + inp, x)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the sumXinE aggregates can now be fetched from the mapping just created:\n",
    "sumXinEaggs = sumXinE2baselineinputs.index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping from sumXinE to E, simply extracted from its name\n",
    "energy_services = list(output[\"ID\"][\"upper_categories\"].keys())\n",
    "for agg in sumXinEaggs:\n",
    "    sumXinE2E[(agg, find_E_in_name(agg, energy_services))] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping from sumXinE to Xs below explicit technologies\n",
    "\n",
    "for sumx in sumXinEaggs:\n",
    "    pure_x_of_sumx = find_X_in_name(sumx, list(output[\"inputprices\"].index))\n",
    "    for t in output[\"ID\"][\"techs_inputs\"]:\n",
    "        for t_x in output[\"ID\"][\"techs_inputs\"][t]:\n",
    "            pure_x_of_t_x = find_true_input(t_x, output[\"ID\"][\"Q2P\"])\n",
    "            if pure_x_of_sumx == pure_x_of_t_x: \n",
    "                sumXinE2X[(sumx, t_x)] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sum of inputs outside of energy services. For ID, this is simply what goes into final goods production. For EOP, inputs used in the entire EOP are added\n",
    "sumXrest2X = {\"ID\":multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"sumXrest\"), \"EOP\":multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"sumXrest\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Y_inp in Y_inputs:\n",
    "    if Y_inp not in output[\"ID\"][\"upper_categories\"]:\n",
    "        #if not an E, add to sumX2X\n",
    "        for module in modules:\n",
    "            sumXrest2X[module][(\"sumXrest_\" + find_true_input(Y_inp, output[\"ID\"][\"Q2P\"]), Y_inp)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the set of aggregates for sumXrest:\n",
    "sumXrestaggs = sumXrest2X[\"ID\"].index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sumx in sumXrestaggs:\n",
    "    pure_x_of_sumx = find_X_in_name(sumx, list(output[\"inputprices\"].index))\n",
    "    for t in output[\"EOP\"][\"techs_inputs\"]:\n",
    "        for t_x in output[\"EOP\"][\"techs_inputs\"][t]:\n",
    "            pure_x_of_t_x = find_true_input(t_x, output[\"EOP\"][\"Q2P\"])\n",
    "            if pure_x_of_sumx == pure_x_of_t_x: \n",
    "                sumXrest2X[\"EOP\"][(sumx, t_x)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change name of the sum of an input to \"sum_x\"\n",
    "# sumX = {\"ID\":sumX[\"ID\"].reset_index(), \"EOP\":sumX[\"EOP\"].reset_index()}\n",
    "# sumX2X = {}\n",
    "# for module in modules:\n",
    "#     sumX[module][\"n\"] = \"sum_\" + sumX[module][\"n\"]\n",
    "#     sumX2X[module] = sumX[module].set_index([\"n\", \"nn\"])[\"sumX\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"phi\")\n",
    "M0 = pd.Series([], name=\"M0\", dtype=\"float64\")\n",
    "M = pd.Series([], name=\"M\", dtype=\"float64\")\n",
    "#Here sets emission intensity equal to 0.1 by construction for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add each input to phi as well (needed for the Phat equation)\n",
    "default_emsint = 0\n",
    "emission_intensities = {\n",
    "    \"oil\":{\n",
    "        \"CO2\":0.2,\n",
    "        \"NOX\":0.2\n",
    "    },\n",
    "    \"electricity\":{\n",
    "        \"SO2\":0.2\n",
    "    }\n",
    "}\n",
    "for m in output[\"EOP\"][\"upper_categories\"].keys():\n",
    "    M0[m] = 5 #Emissions default simply chosen to be 5\n",
    "    M[m] = 5\n",
    "    for x in sumXrest2X[\"EOP\"].append(sumXinE2X).index.get_level_values(1):\n",
    "        true_input = find_true_input(x, output[\"ID\"][\"Q2P\"].append(output[\"EOP\"][\"Q2P\"]))\n",
    "        if (true_input in emission_intensities and m in emission_intensities[true_input]):\n",
    "            phi[(m, x)] = emission_intensities[true_input][m]\n",
    "        else:\n",
    "            phi[(m, x)] = default_emsint\n",
    "    #baseline technologies' inputs\n",
    "    for basetech in output[\"ID\"][\"basetech_inputs\"]:\n",
    "        for x in output[\"ID\"][\"basetech_inputs\"][basetech]:\n",
    "            true_input = find_true_input(x, output[\"ID\"][\"Q2P\"])\n",
    "            if (true_input in emission_intensities and m in emission_intensities[true_input]):\n",
    "                phi[(m, x)] = emission_intensities[true_input][m]\n",
    "            else:\n",
    "                phi[(m, x)] = default_emsint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emission prices,  and theta which measures the potentials of components.\n",
    "pM = M.copy()\n",
    "pM[:] = 50\n",
    "pM.name = \"pM\"\n",
    "pM.index.name = \"n\"\n",
    "\n",
    "pMhat = M.copy()\n",
    "pMhat[:] = 50\n",
    "pMhat.name = \"pMhat\"\n",
    "pMhat.index.name = \"n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2: Adding parameters to the database (starting values and share parameters)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to construct a database that contains all the share-parameters that we can deduce from technology data, as well as appropriate starting values for endogenous variables. These starting values will be set to the value that they would have if the entire tree was Leontief.\n",
    "The end goal is to make sure the database contained by `nt` includes all these parameters and starting values. \n",
    "To do so, we construct an empty database, add the share-parameters and starting values to this, and then finally merge that database with the one already in `nt`.\n",
    "\n",
    "The GPM database of the nesting_tree instance (`nt`) does not contain the $\\mu$ parameters calculated from technology data yet.\\\n",
    "The $\\mu$-parameters are stored under the key of the same name in `output`.\\\n",
    "Let's check out the database of `nt` now, to see that it does not include any symbol called $\\mu$ yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database nt.database is of type <class 'DataBase.GPM_database'>\n",
      "Does the database include a symbol called mu? \n",
      "NO!\n"
     ]
    }
   ],
   "source": [
    "print(\"The database nt.database is of type \" + str(type(nts[\"ID\"].database)))\n",
    "print(\"Does the database include a symbol called mu? \") \n",
    "if \"mu\" in nts[\"ID\"].database.series:\n",
    "    print(\"YES!\")\n",
    "else:\n",
    "    print(\"NO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an empty database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = {\"ID\":DataBase.GPM_database(), \"EOP\":DataBase.GPM_database()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the share-parameters from technology data in an object called `mu`. This does not contain all share-parameters of the tree (e.g. it does not include the share parameters of the inputs under baseline technology goods, or the share parameters for technology goods under components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = {\"ID\":output[\"ID\"][\"mu\"].copy(), \"EOP\":output[\"EOP\"][\"mu\"].copy()}\n",
    "# for module in modules:\n",
    "#     mu[module].name = module + \"_\" + mu[module].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the mu parameters (prints just the five first entries here).\\\n",
    "Note: The mu-object is a series with a multiindex, where the first level is called `n` and the second level `nn`. The first level contains branches and the second level contains nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n                 nn  \n",
       "ID_1_electricity  ID_1    0.475\n",
       "ID_1_oil          ID_1    0.475\n",
       "ID_1_K            ID_1    4.050\n",
       "C_EL_1            EL      0.050\n",
       "U_ID_1_1          ID_1    0.500\n",
       "Name: mu, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[\"ID\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate starting values (corresponding to the solution if the entire tree was Leontief).\n",
    "For demands/quantities, we use the fact that Leontief demand is given by \n",
    "$$q_j = \\mu_j \\left(\\frac{p_i}{p_j}\\right)^\\sigma q_i = \\mu_j q_i$$ for CES demand where $i$ refers to a node and $j$ refers to the branch. The CET and the MNL form is identical under Leontief.\\\n",
    "For prices, we generally use that when we know the price of each branch under a node as well as the quantities of these branches, the zero profit condition can be rearranged to give us the price of the node:\n",
    "$$ q_i p_i = \\sum_j q_j p_j \\quad \\Leftrightarrow \\quad  p_i = \\frac{\\sum_j q_j p_j}{q_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output quantities are held in the `qS` object. Output quantities are held fixed in the partial equilibrum (the output prices are the variables that adjust), and we simply set them to `output_quantity` in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_quantity_Yout = 100 * len(Y_inputs) / len(Y_outputs) #Makes qD[E] = 100 by construction\n",
    "output_quantity_M = 100\n",
    "qS = {\"ID\":pd.Series([], name=\"qS\", dtype=\"float64\"), \"EOP\":pd.Series([], name=\"qS\", dtype=\"float64\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`qS` is now an empty series to which we add the value of 100 for each output of the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nt in nts:\n",
    "    for out in nts[nt].database.series[nt+\"_out\"]:\n",
    "        if nt == \"ID\":\n",
    "            quantity = output_quantity_Yout\n",
    "        elif nt == \"EOP\":\n",
    "            quantity = output_quantity_M\n",
    "        qS[nt][out] = quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other quantities are kept in the object `qD`, which we initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qD = {\"ID\":pd.Series([], name=\"qD\", dtype=\"float64\"), \"EOP\":pd.Series([], name=\"qD\", dtype=\"float64\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we calculate the composite Y and the quantities of the inputs for Y (E + dX rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qD[\"ID\"][\"Y\"] = sum(qS[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Yinp in Y_inputs:\n",
    "    qD[\"ID\"][Yinp] = mu[\"ID\"].loc[(Yinp, \"Y\")] * qD[\"ID\"][\"Y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we calculate components' starting values for input-displacing (we did it for EOP with qS, because components are outputs there). \\\n",
    "We use the demand equation stated earlier (multiplication of share-parameter and relevant node/component). This calculates quantities for all components, including baseline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for E in output[\"ID\"][\"upper_categories\"]:\n",
    "    for C in output[\"ID\"][\"upper_categories\"][E]:\n",
    "        qD[\"ID\"][C] = mu[\"ID\"].loc[(C, E)] * qD[\"ID\"][E]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use that we have estimates of U to set these (current coverages split according to overlap), and then calculate the $\\mu$s residually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, curr_coverage in output[\"ID\"][\"current_coverages\"].iteritems():\n",
    "    qD[\"ID\"][index[0]] = curr_coverage * qD[\"ID\"][index[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\mu$s of technology goods (in their component nest) residually. This includes the share-parameters for the baseline technology goods $\\bar U$. Since we still have not set the starting values for the quantities of these baseline technology goods, we set these using the share-parameters that are calculated here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in output[\"ID\"][\"components\"]:\n",
    "    #The ':-1' leaves out the baseline technology good, which we handle separately afterwards\n",
    "    nonbase_U = output[\"ID\"][\"components\"][C][:-1]\n",
    "    base_mu = 1\n",
    "    for U in nonbase_U:\n",
    "        mu[\"ID\"][(U, C)] =  qD[\"ID\"][U]/qD[\"ID\"][C]\n",
    "        base_mu -= mu[\"ID\"][(U, C)]\n",
    "    #Quantities of baseline U\n",
    "    mu[\"ID\"][(output[\"ID\"][\"components\"][C][-1], C)] = base_mu\n",
    "    qD[\"ID\"][output[\"ID\"][\"components\"][C][-1]] = base_mu * qD[\"ID\"][C]\n",
    "    if base_mu <= 0:\n",
    "        print(C)\n",
    "        print(nonbase_U)\n",
    "        raise Exception(\"base_mu is not positive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For end of pipe, we simply set the share-parameters of the technology goods under components as $1/N$ where $N$ is the number of branches/technology goods under a given component. Having set these, we can calculate the corresponding quantities using the CES Leontief demand equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in output[\"EOP\"][\"components\"]:\n",
    "    for U in output[\"EOP\"][\"components\"][C]:\n",
    "        mu[\"EOP\"].loc[(U, C)] = 1/len(output[\"EOP\"][\"components\"][C])\n",
    "        qD[\"EOP\"][U] = mu[\"EOP\"].loc[(U, C)] * qS[\"EOP\"][C]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we calculate the starting values of technologies $\\tau$ as the sum of their relevant $U$, since the CET function should be scale-preserving.\\\n",
    "The drawback here, for EOP only, is that the quantities of $U$ do not necessarily adhere to the relative sizes of their share-parameters (which are set based on the technology catalog). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    for tech in output[module][\"techs\"]:\n",
    "        qD[module][tech] = qD[module][output[module][\"techs\"][tech]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we set the starting values of the inputs $X$ that go into technologies. These again use the demand equation. The share-parameters of these were given directly from technology data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    techs = output[module][\"techs_inputs\"]\n",
    "    for tech in techs:\n",
    "        for inp in techs[tech]:\n",
    "            qD[module][inp] = mu[module].loc[(inp, tech)] * qD[module][tech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the quantity of the IO-technology as the sum of the quantities of the goods ($U_0$ and $C_0$) that it provides. Afterwards, calculate the relevant share parameters using the fraction of IO-tech to the goods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantity of the baseline technologies\n",
    "for basetech in output[\"ID\"][\"basetechs\"]:\n",
    "    qD[\"ID\"][basetech] = 0\n",
    "    for baseU in output[\"ID\"][\"basetechs\"][basetech]:\n",
    "        qD[\"ID\"][basetech] += qD[\"ID\"][baseU]\n",
    "    #share parameters for each the non-replacing baseline technologies:\n",
    "    for baseU in output[\"ID\"][\"basetechs\"][basetech]:\n",
    "        mu[\"ID\"][(baseU, basetech)] = qD[\"ID\"][baseU] / qD[\"ID\"][basetech]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part contains the setting of starting values for prices.\n",
    "The prices of inputs (the very bottom of the tree) are fully exogenous, whereas all other prices are endogenous. The prices of outputs (those whose quantities are contained in `qS` are kept in the object `PbT` (refers to \"prices before taxes\") whereas the rest of the prices are kept in `PwT`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects for storing prices of goods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "PwThat = {\"ID\":pd.Series([], name=\"PwThat\", dtype=\"float64\"), \"EOP\":pd.Series([], name=\"PwThat\", dtype=\"float64\")}\n",
    "PwT = {\"ID\":pd.Series([], name=\"PwT\", dtype=\"float64\"), \"EOP\":pd.Series([], name=\"PwT\", dtype=\"float64\")}\n",
    "PbT = {\"ID\":pd.Series([], name=\"PbT\", dtype=\"float64\"), \"EOP\":pd.Series([], name=\"PbT\", dtype=\"float64\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prices of inputs are also stated in the catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    for t, inputs in output[module][\"techs_inputs\"].items():\n",
    "        for inp in inputs:\n",
    "            PwT[module][inp] = output[\"inputprices\"][inp.split(\"_\")[-1]]\n",
    "            p = output[\"inputprices\"][inp.split(\"_\")[-1]]\n",
    "            #Add emission prices to Phat\n",
    "            taxes = 0\n",
    "            for m in pM.index:\n",
    "                taxes += phi[(m, inp)] * pM[m]\n",
    "            PwThat[module][inp] = p + taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prices on the dX in final goods production\n",
    "for Y_inp in Y_inputs:\n",
    "    if Y_inp not in output[\"ID\"][\"upper_categories\"].keys():\n",
    "        p = output[\"inputprices\"][find_true_input(Y_inp, output[\"ID\"][\"Q2P\"])]\n",
    "        PwT[\"ID\"][Y_inp] = p\n",
    "        taxes = 0\n",
    "        for m in pM.index:\n",
    "            taxes += phi[(m, Y_inp)] * pM[m]\n",
    "        PwThat[\"ID\"][Y_inp] = p + taxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the prices of technologies: $p^\\tau$. These correspond to the weighted average of the prices of its inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    for t, inputs in output[module][\"techs_inputs\"].items():\n",
    "        PwThat[module][t] = pd.concat([PwThat[module][inputs], qD[module][inputs]], axis=1).product(axis=1).sum() / qD[module][t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These prices are equal to unit costs by construction, which we check here for good measure. The differences between prices and unit costs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech\n",
       "ID_1   -14.25\n",
       "ID_2   -12.10\n",
       "ID_3     0.00\n",
       "ID_4    -2.00\n",
       "ID_5    -8.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(output[\"ID\"][\"unit_costs\"].set_index(\"tech\")[\"unit_cost\"] - PwThat[\"ID\"][output[\"ID\"][\"unit_costs\"][\"tech\"]], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $p^U$, we simply assume $p^U = p^\\tau$, which, since the share-parameters in the CET nest splitting $\\tau$ into its produced technology goods sum to one, is consistent with zero profits (mroe generally, scale preservation ensures zero profits with this assumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    for t in output[module][\"techs\"]:\n",
    "        for U in output[module][\"techs\"][t]:\n",
    "            PwThat[module][U] = PwThat[module][t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prices on components for end of pipe should be allocated to PbT because that includes the prices of outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, U_list in output[\"EOP\"][\"components\"].items():\n",
    "    PbT[\"EOP\"][C] = pd.concat([PwThat[\"EOP\"][U_list], qD[\"EOP\"][U_list]], axis=1).product(axis=1).sum() / qS[\"EOP\"][C]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert baseline input quantities and baseline technology good prices (only relevant for ID since baselines do not exist in EOP).\n",
    "\n",
    "This also (for now, should be set with input-output macro data later) sets the share-parameters of the inputs for the baseline technology goods. It assumes that the baseline uses all energy inputs in equal proportions and that these share-parameters sum to 1. Using these share-parameters, the corresponding quantities are added to `qD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for basetech in output[\"ID\"][\"basetech_inputs\"]:\n",
    "    inputs = output[\"ID\"][\"basetech_inputs\"][basetech]\n",
    "    for inp in inputs:\n",
    "        mu[\"ID\"][(inp, basetech)] = 1/len(inputs)\n",
    "        PwT[\"ID\"][inp] = output[\"inputprices\"][inp.split(\"_\")[-1]]\n",
    "        p = output[\"inputprices\"][inp.split(\"_\")[-1]]\n",
    "        taxes = 0\n",
    "        for m in pM.index:\n",
    "            taxes += phi[(m, inp)] * pM[m]\n",
    "        PwThat[\"ID\"][inp] = p + taxes\n",
    "        qD[\"ID\"][inp] = mu[\"ID\"][(inp, basetech)] * qD[\"ID\"][basetech]\n",
    "    #Price of the IO technology\n",
    "    PwThat[\"ID\"][basetech] = pd.concat([PwThat[\"ID\"][inputs], qD[\"ID\"][inputs]], axis=1).product(axis=1).sum() / qD[\"ID\"][basetech]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price of each output from the baseline technologies are simply set to the price that they themselves have \n",
    "for basetech in output[\"ID\"][\"basetechs\"]:\n",
    "    for U0 in output[\"ID\"][\"basetechs\"][basetech]:\n",
    "        PwThat[\"ID\"][U0] = PwThat[\"ID\"][basetech] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantities and prices of inputs to replacement-baseline-technologies and the cost of these as well:\n",
    "# for base_U, inputs in output[\"ID\"][\"baseline_U_inputs\"].items():\n",
    "#     for inp in inputs:\n",
    "#         qD[\"ID\"][inp] = mu[\"ID\"][(inp, base_U)] * qD[\"ID\"][base_U]\n",
    "#         PwT[\"ID\"][inp] = output[\"inputprices\"][inp.split(\"_\")[-1]] #Actual prices\n",
    "#         p = output[\"inputprices\"][inp.split(\"_\")[-1]]\n",
    "#         taxes = 0\n",
    "#         for m in pM.index:\n",
    "#             taxes += phi[(m, inp)] * pM[m]\n",
    "#         PwThat[\"ID\"][inp] = p + taxes\n",
    "#     PwThat[\"ID\"][base_U] =  pd.concat([PwThat[\"ID\"][inputs], qD[\"ID\"][inputs]], axis=1).product(axis=1).sum() / qD[\"ID\"][base_U]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prices of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, U_list in output[\"ID\"][\"components\"].items():\n",
    "    PwThat[\"ID\"][C] = pd.concat([PwThat[\"ID\"][U_list], qD[\"ID\"][U_list]], axis=1).product(axis=1).sum() / qD[\"ID\"][C]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prices of energy services (\"upper categories\" in ID). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for E, C_list in output[\"ID\"][\"upper_categories\"].items():\n",
    "    PwThat[\"ID\"][E] = pd.concat([PwThat[\"ID\"][C_list], qD[\"ID\"][C_list]], axis=1).product(axis=1).sum() / qD[\"ID\"][E]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price of composite of Y and outputs of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "PwThat[\"ID\"][\"Y\"] = pd.concat([PwThat[\"ID\"][Y_inputs], qD[\"ID\"][Y_inputs]], axis=1).product(axis=1).sum() / qD[\"ID\"][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price of final goods are equal to price of Y\n",
    "for Y_out in Y_outputs:\n",
    "    PbT[\"ID\"][Y_out] = PwThat[\"ID\"][\"Y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add the calculated values to the (still) empty database `db` instantiated earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we merge the first databases into the nesting tree objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    qS[module].index.name = \"n\"\n",
    "    qD[module].index.name = \"n\"\n",
    "    PwThat[module].index.name = \"n\"\n",
    "    PwT[module].index.name = \"n\"\n",
    "    PbT[module].index.name = \"n\"\n",
    "    dbs[module][\"qS\"] = qS[module]\n",
    "    dbs[module][\"qD\"] = qD[module]\n",
    "    dbs[module][\"PwThat\"] = PwThat[module]\n",
    "    dbs[module][\"PbT\"] = PbT[module]\n",
    "    dbs[module][\"mu\"] = mu[module]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `db` with the database attached to the nesting tree object `nt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    DataBase.GPM_database.merge_dbs(nts[module].database, dbs[module], \"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a confirmation that this went succesfully, we check that the databse in `nt` contains a symbol called 'mu':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n                 nn  \n",
       "ID_1_electricity  ID_1    0.475\n",
       "ID_1_oil          ID_1    0.475\n",
       "ID_1_K            ID_1    4.050\n",
       "C_EL_1            EL      0.050\n",
       "U_ID_1_1          ID_1    0.500\n",
       "Name: mu, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts[\"ID\"].database.series[\"mu\"].vals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We now proceed to use the class *abate*, a childclass of *gmspython*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sets used for calibration to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g_exo_vals consists of $\\bar \\sigma$ and $\\bar \\mu$. These are targets in the minimzation object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bar \\sigma$ parameters used for the minimization object. These are the sigmas in the MNL nests (C->U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmabar = {\"ID\":pd.Series([], name=\"sigmabar\", dtype=\"float64\"), \"EOP\":pd.Series([], name=\"sigmabar\", dtype=\"float64\")}\n",
    "for c in output[\"ID\"][\"components\"].keys():\n",
    "    sigmabar[\"ID\"][c] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bar \\mu$ parameters used for minimization object. These are the share parameters in the CET split from technologies to technology goods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mubar = {\"ID\":mu[\"ID\"].loc[pd.IndexSlice[mu[\"ID\"].index.get_level_values(0).isin(flatten_list(list(output[\"ID\"][\"techs\"].values()))), \\\n",
    "                     mu[\"ID\"].index.get_level_values(1).isin(list(output[\"ID\"][\"techs\"].keys()))]]}\n",
    "mubar[\"ID\"].name = \"mubar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g_tech_endo consists of parameters that are endogenized in the calibration procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_EC = mu[\"ID\"].loc[pd.IndexSlice[pd.Series(mu[\"ID\"].index.get_level_values(0).str.startswith(\"C\")), \\\n",
    "                     pd.Series(mu[\"ID\"].index.get_level_values(1).str.startswith(\"E\"))]].index\n",
    "\n",
    "mu_IOtech = mu[\"ID\"].loc[pd.IndexSlice[mu[\"ID\"].index.get_level_values(0).str.startswith(\"IO\"), mu[\"ID\"].index.get_level_values(0).str.startswith(\"IO\")]].index\n",
    "\n",
    "sigma_CU = sigmabar[\"ID\"].index\n",
    "sigma_CU.name = \"n\"\n",
    "\n",
    "mu_CU = mu[\"ID\"].loc[mu[\"ID\"].index.get_level_values(0).isin(flatten_list(output[\"ID\"][\"components\"].values())), mu[\"ID\"].index.get_level_values(1).isin(output[\"ID\"][\"components\"].keys())].index\n",
    "mu_CU.name = \"n\"\n",
    "\n",
    "mu_tautoU = mu[\"ID\"].loc[pd.IndexSlice[mu[\"ID\"].index.get_level_values(0).str.startswith(\"U\"), mu[\"ID\"].index.get_level_values(1).isin(output[\"ID\"][\"techs\"].keys())]].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Share-parameters of Leontief technologies (to be kept exogenous throughout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.IndexSlice[pd.Series(mu[\"ID\"].index.get_level_values(1).isin(output[\"ID\"][\"techs\"].keys())), pd.Series(mu[\"ID\"].index.get_level_values(1).isin(output[\"ID\"][\"techs\"].keys()))]\n",
    "\n",
    "# t2 = pd.IndexSlice[pd.Series(mu[\"ID\"].index.get_level_values(1).isin(output[\"ID\"][\"baseline_U_inputs\"].keys())), \\\n",
    "#                    pd.Series(mu[\"ID\"].index.get_level_values(1).isin(output[\"ID\"][\"baseline_U_inputs\"].keys()))]\n",
    "\n",
    "mu_leontief_techs = mu[\"ID\"].loc[t].index\n",
    "#.append(mu[\"ID\"].loc[t].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_endoincalib_mu = {\"ID\":mu_EC.append(mu_IOtech).append(mu_CU).append(mu_tautoU), \"EOP\":None}\n",
    "tech_endoincalib_sigma = {\"ID\":sigma_CU, \"EOP\":None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g_endovars_exoincalib includes the endogenous variables that we exogenize in calibration because we have data on them (C due to potentials, sum of U due to current applications, sum of dX for IO tech and replacing tech due to IO data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping from technology goods to \n",
    "U2E = multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"map_E2E\")\n",
    "for E in output[\"ID\"][\"upper_categories\"]:\n",
    "    for C in output[\"ID\"][\"upper_categories\"][E]:\n",
    "        for U in output[\"ID\"][\"components\"][C]:\n",
    "            U2E[(U, E)] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sumU object is constructed because we need to calibrate to those. sumU hits current application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumU = {\"ID\":multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"sumU\"), \"EOP\":multiindex_series(idx_level_names=[\"n\", \"nn\"], series_name=\"sumU\")}\n",
    "for module in modules:\n",
    "    for t in output[module][\"techs\"]:\n",
    "        for U in output[module][\"techs\"][t]:\n",
    "            C = find_key_from_value(output[module][\"components\"], U)\n",
    "            upper = find_key_from_value(output[module][\"upper_categories\"], C)\n",
    "            sumU[module][(\"sumU_\" + t + \"_\" + upper, U)] = qD[module][U]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumU_map = {\"ID\":sumU[\"ID\"].index, \"EOP\":sumU[\"EOP\"].index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsumU = sumU.copy()\n",
    "for module in modules:\n",
    "    qsumU[module].index = qsumU[module].index.droplevel(1)\n",
    "    qsumU[module] = qsumU[module].groupby(\"n\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumUaggs = {}\n",
    "# sumXaggs = {}\n",
    "for module in modules:    \n",
    "    sumUaggs[module] = sumU_map[module].get_level_values(0).unique()\n",
    "#     sumXaggs[module] = sumX2X[module].get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endovars_exoincalib_sumU = sumU_map.copy()\n",
    "# endovars_exoincalib_sumX = sumX\n",
    "endovars_exoincalib_C = {\"ID\":mu_EC.get_level_values(0), \"EOP\":None}\n",
    "endovars_exoincalib_E = {\"ID\":mu_EC.get_level_values(1).unique(), \"EOP\":None}\n",
    "endovars_exoincalib_E[\"ID\"].name = \"n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calib_values_currentapplications = pd.concat([qD[qD.index.str.startswith(\"U\") & ~qD.index.str.contains(\"EOP\")], qD[qD.index.str.startswith(\"C\")]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calib_values_potentials = mu.loc[pd.IndexSlice[pd.Series(mu.index.get_level_values(0).str.startswith(\"C\")), \\\n",
    "#                                  pd.Series(mu.index.get_level_values(1).str.startswith(\"E\"))]]\n",
    "calib_values_potentials = {}\n",
    "for module in modules:\n",
    "    calib_values_potentials[module] = output[module][\"coverage_potentials\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dict: tech_dbs with databases for ID and EOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_dbs = {\"ID\":DataBase.GPM_database(), \"EOP\":DataBase.GPM_database()}\n",
    "alwaysexo_mu = {\"ID\":mu[\"ID\"].drop(tech_endoincalib_mu[\"ID\"]).index, \"EOP\":mu[\"EOP\"].index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    tech_dbs[module][\"PwT\"] = PwT[module] #New basic prices\n",
    "    #db[\"endovars_exoincalib_sumU\"] = endovars_exoincalib_sumU\n",
    "    #db[\"endovars_exoincalib_sumX\"] = endovars_exoincalib_sumX\n",
    "    tech_dbs[module][module + \"_\" +\"params_alwaysexo_mu\"] = alwaysexo_mu[module]\n",
    "    tech_dbs[module][\"calib_values_currentapplications\"] = qsumU[module]\n",
    "    tech_dbs[module][\"calib_values_potentials\"] = calib_values_potentials[module]\n",
    "    if module == \"ID\":\n",
    "        tech_dbs[module][module + \"_\" + \"endovars_exoincalib_E\"] = endovars_exoincalib_E[module]\n",
    "        tech_dbs[module][module + \"_\" + \"endovars_exoincalib_C\"] = endovars_exoincalib_C[module]\n",
    "        tech_dbs[module][module + \"_\" +\"tech_endoincalib_mu\"] = tech_endoincalib_mu[module]\n",
    "        tech_dbs[module][module + \"_\" +\"tech_endoincalib_sigma\"] = tech_endoincalib_sigma[module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimization stuff\n",
    "for module in modules:\n",
    "    tech_dbs[module][\"minobj\"] = 1\n",
    "    if module == \"ID\":\n",
    "        tech_dbs[module][\"minobj_mu\"] = mubar[module]\n",
    "        tech_dbs[module][\"minobj_sigma\"] = sigmabar[module]\n",
    "        tech_dbs[module][\"minobj_mu_subset\"] = mubar[module].index\n",
    "        tech_dbs[module][\"minobj_sigma_subset\"] = sigmabar[module].index\n",
    "        tech_dbs[module][\"weight_sigma\"] = 1\n",
    "        tech_dbs[module][\"weight_mu\"] = 1\n",
    "    if module == \"EOP\":\n",
    "        tech_dbs[module][\"weight_sigmaG\"] = 1\n",
    "        tech_dbs[module][\"weight_muG\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in modules:\n",
    "    tech_dbs[module][module + \"_\" +\"sumUaggs\"] = sumU_map[module].get_level_values(0).unique()\n",
    "    tech_dbs[module][module + \"_\" +\"sumU2U\"] = sumU_map[module]\n",
    "    tech_dbs[module][\"qsumU\"] = qsumU[module]\n",
    "#     dbs[module][\"qsumU\"].name = \"qsumU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregates for IO data\n",
    "tech_dbs[\"ID\"][\"sumXinEaggs\"] = sumXinEaggs\n",
    "tech_dbs[\"ID\"][\"sumXrestaggs\"] = sumXrestaggs\n",
    "for module in modules:\n",
    "    tech_dbs[module][\"map_sumXrest2X_\" + module] = sumXrest2X[module].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n                   nn              \n",
       "sum_EL_electricity  ID_1_electricity   NaN\n",
       "                    ID_2_electricity   NaN\n",
       "                    ID_4_electricity   NaN\n",
       "sum_EL_oil          ID_1_oil           NaN\n",
       "                    ID_2_oil           NaN\n",
       "                    ID_5_oil           NaN\n",
       "sum_EL_inp3         ID_3_inp3          NaN\n",
       "                    ID_4_inp3          NaN\n",
       "sum_EL_inp4         ID_3_inp4          NaN\n",
       "                    ID_5_inp4          NaN\n",
       "sum_EL_inp5         ID_3_inp5          NaN\n",
       "                    ID_4_inp5          NaN\n",
       "sum_EL_K            ID_1_K             NaN\n",
       "                    ID_2_K             NaN\n",
       "                    ID_3_K             NaN\n",
       "                    ID_4_K             NaN\n",
       "                    ID_5_K             NaN\n",
       "sum_EH_electricity  ID_1_electricity   NaN\n",
       "                    ID_2_electricity   NaN\n",
       "                    ID_4_electricity   NaN\n",
       "sum_EH_oil          ID_1_oil           NaN\n",
       "                    ID_2_oil           NaN\n",
       "                    ID_5_oil           NaN\n",
       "sum_EH_inp3         ID_3_inp3          NaN\n",
       "                    ID_4_inp3          NaN\n",
       "sum_EH_inp4         ID_3_inp4          NaN\n",
       "                    ID_5_inp4          NaN\n",
       "sum_EH_inp5         ID_3_inp5          NaN\n",
       "                    ID_4_inp5          NaN\n",
       "sum_EH_K            ID_1_K             NaN\n",
       "                    ID_2_K             NaN\n",
       "                    ID_3_K             NaN\n",
       "                    ID_4_K             NaN\n",
       "                    ID_5_K             NaN\n",
       "sum_ER_electricity  ID_1_electricity   NaN\n",
       "                    ID_2_electricity   NaN\n",
       "                    ID_4_electricity   NaN\n",
       "sum_ER_oil          ID_1_oil           NaN\n",
       "                    ID_2_oil           NaN\n",
       "                    ID_5_oil           NaN\n",
       "sum_ER_inp3         ID_3_inp3          NaN\n",
       "                    ID_4_inp3          NaN\n",
       "sum_ER_inp4         ID_3_inp4          NaN\n",
       "                    ID_5_inp4          NaN\n",
       "sum_ER_inp5         ID_3_inp5          NaN\n",
       "                    ID_4_inp5          NaN\n",
       "sum_ER_K            ID_1_K             NaN\n",
       "                    ID_2_K             NaN\n",
       "                    ID_3_K             NaN\n",
       "                    ID_4_K             NaN\n",
       "                    ID_5_K             NaN\n",
       "Name: map_sumXinE2X, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumXinE2X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mappings related to new IO structure and calibration\n",
    "tech_dbs[\"ID\"][\"map_sumXinE2X\"] = sumXinE2X.index\n",
    "tech_dbs[\"ID\"][\"map_sumXinE2E\"] = sumXinE2E.index\n",
    "tech_dbs[\"ID\"][\"map_sumXinE2baselineinputs\"] = sumXinE2baselineinputs.index\n",
    "tech_dbs[\"ID\"][\"map_U2E\"] = U2E.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qsumX = {\"ID\":pd.Series([], name=\"qsumX\", dtype=\"float64\"), \"EOP\":pd.Series([], name=\"qsumX\", dtype=\"float64\")}\n",
    "\n",
    "qsumX = pd.Series([], name=\"qsumX\", dtype=\"float64\")\n",
    "for sumx in sumXinEaggs:\n",
    "    total = 0\n",
    "    for x in sumXinE2X.index[sumXinE2X.index.get_level_values(0).isin([sumx])].get_level_values(1):\n",
    "        total += qD[\"ID\"][x]\n",
    "    qsumX[sumx] = total\n",
    "\n",
    "for sumx in sumXrestaggs:\n",
    "    total = 0\n",
    "    for x in sumXrest2X[\"EOP\"].index[sumXrest2X[\"EOP\"].index.get_level_values(0).isin([sumx])].get_level_values(1):\n",
    "        if x in qD[\"EOP\"]:\n",
    "            total += qD[\"EOP\"][x]\n",
    "        elif x in qD[\"ID\"]:\n",
    "            total += qD[\"ID\"][x]\n",
    "        else:\n",
    "            raise Exception(\"WHAT\")\n",
    "    qsumX[sumx] = total\n",
    "    \n",
    "qsumX.index.name = \"n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumX2X[module].loc[pd.IndexSlice[pd.Series(sumX2X[module].get_level_values(0).isin([sumx]))]]\n",
    "# pd.IndexSlice[pd.Series(mu[\"ID\"].index.get_level_values(1).isin(sumx)), pd.Series(mu[\"ID\"].index.get_level_values(1).isin(output[\"ID\"][\"techs\"].keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for module in modules:\n",
    "tech_dbs[\"ID\"][\"qsumX\"] = qsumX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emission accounts stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the sumX-variable to the emission intensity variable (phi)\n",
    "\n",
    "for m in output[\"EOP\"][\"upper_categories\"].keys():\n",
    "    for sumx in qsumX.index:\n",
    "        true_input = find_X_in_name(sumx, list(output[\"inputprices\"].index))\n",
    "        if true_input in emission_intensities.keys():\n",
    "            if m in emission_intensities[true_input]:\n",
    "                phi[(m, sumx)] = emission_intensities[true_input][m]\n",
    "                continue\n",
    "        phi[(m, sumx)] = default_emsint\n",
    "#Update index names of M0 and M\n",
    "M0.index.name = \"n\"\n",
    "M.index.name = \"n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store in database\n",
    "tech_dbs[\"ID\"][\"phi\"] = phi\n",
    "tech_dbs[\"ID\"][\"map_M2X\"] = phi.index\n",
    "tech_dbs[\"ID\"][\"M0\"] = M0\n",
    "tech_dbs[\"EOP\"][\"M\"] = M\n",
    "tech_dbs[\"ID\"][\"M_subset\"] = M0.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping that shows which components in EOP contribute to the abatement of which emission types\n",
    "map_M2C = multiindex_series(idx_level_names=[\"n\", \"nn\"], idx_name=\"map_M2C\")\n",
    "for m in output[\"EOP\"][\"upper_categories\"]:\n",
    "    for c in output[\"EOP\"][\"upper_categories\"][m]:\n",
    "        map_M2C[(m, c)] = np.nan\n",
    "map_M2C = map_M2C.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_dbs[\"EOP\"][\"map_M2C\"] = map_M2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#technical parameters in G-functions (muG and sigmaG)\n",
    "muG = pd.Series([], name=\"muG\", dtype=\"float64\")\n",
    "sigmaG = pd.Series([], name=\"sigmaG\", dtype=\"float64\")\n",
    "for c in map_M2C.get_level_values(1):\n",
    "    muG[c] = 0\n",
    "    sigmaG[c] = 1\n",
    "\n",
    "\n",
    "muG.index.name = \"n\"\n",
    "sigmaG.index.name = \"n\"\n",
    "# EOP_C_subset = muG.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOP_C_subset.name = \"n\"\n",
    "# tech_dbs[\"EOP\"][\"EOP_C_subset\"] = EOP_C_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potentials\n",
    "theta = calib_values_potentials[\"EOP\"].copy()\n",
    "theta.index = theta.index.droplevel(1)\n",
    "theta.name = \"theta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibration procedure unfixes all muG and sigmaG.\n",
    "muGbar = muG.copy()\n",
    "sigmaGbar = sigmaG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to database\n",
    "module = \"EOP\"\n",
    "tech_dbs[module][\"pM\"] = pM\n",
    "tech_dbs[module][\"muG\"] = muG\n",
    "tech_dbs[module][\"sigmaG\"] = sigmaG\n",
    "tech_dbs[module][\"minobj_muG\"] = muGbar\n",
    "tech_dbs[module][\"minobj_sigmaG\"] = sigmaGbar\n",
    "tech_dbs[module][\"theta\"] = theta\n",
    "\n",
    "\n",
    "module = \"ID\"\n",
    "tech_dbs[module][\"pMhat\"] = pMhat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we adjust the prices according to the emission content of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3: The model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a gams model using a *gmspython* childclass (*abate*). We build the partial equilibrium model from the following principles:\n",
    "* The firm takes input prices as given. These are prices with taxes ('PwThat') that are defined over the global set *inp*. In this case this includes e.g. the price on electricity and capital.\n",
    "* The firm further takes the quantity of supply as given (it has to be either this or output prices for the model to be square). We denote the quantity of supply 'qS', and define it over the subset of goods that are outputs from the sector *out*. \n",
    "* The firm's demand for intermediate goods, and their prices are endogenous to the firm: In our case this involves $\\tau$, $U$ and $C$ in ID and only $\\tau$ and $U$ in EOP. These intermediate goods are not traded on any market, but is simply a construct we use to build the nests. In this way the quantity of $U$ is both supplied, and demanded by the firm/sector itself. As we do not need both a supply and demand variable (they are the same in this case), we let the quantity/prices for intermediate goods go under the variables 'qD'/'PwThat', defined over the subset *int*.\n",
    "* The demand for inputs is also endogenous to the firm. We denote this 'qD' defined over the subset of goods 'inp'.\n",
    "* As briefly mentioned above, we either have to let the output prices / quantities be endogeonous (and the other exogenous) for the module to be square. In this case we let the price on outputs be endogenous. We denote the price 'PbT' for price before taxes. This is defined over the subset *out*. Distinguishing between PbT and PwThat allows for the flexibility of including a tax module / including a mark-up on profits at a later point.\n",
    "\n",
    "We will get back to the way we initialize the *gmspython* module next; here we initialize the class to be able to print the variables needed for this specific model.\n",
    "The model, denoted `m`, is an instance of the class `abate` which is itself a childclass of the more general `gmspython` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = abatement.abate(nt=nts[\"ID\"], tech_db=tech_dbs[\"ID\"], work_folder=work_folder, use_EOP={\"tech_db\":tech_dbs[\"EOP\"], \"nt\":nts[\"EOP\"]}, **{'data_folder': gams_folder, \"name\":\"Abatement\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model.database.update_all_sets(clean_up=False) #Makes n include the sum variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model.functions = {\"std_pdf\":\"$FUNCTION std_pdf({x}): ((1/(sqrt(2*Pi)))*exp(-(Sqr({x}))/2)) $ENDFUNCTION\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that running a model requires constructing three methods/properties for `m`:\n",
    "\n",
    "1. `m.initialize_variables()`\n",
    "2. `m.endo_groups` and `m.exo_groups`\n",
    "3. `m.add_blocks()`\n",
    "\n",
    "We briefly review each in turn.\n",
    "\n",
    "`m.initialize_variables()` sets default initial values for the variables and parameters that are not already present in the attached database (which we constructed earlier). For example, we did not specify the values for the mark-up parameters anywhere, so the method `initialize_variables()` *must* specify the value that these parameters should have. We can see that in this case they will simply be set to 1 (no markup):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default values for markups are zero, i.e. no markups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the method using the keyword argument `check_variables:True`. This makes the program check whether the database contains all the necessary values of a specific variable/parameter (say, $\\mu$), and if not, merges the default value (in this case equal to 1) onto the series of share-parameters already contained in the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'map_sumXinE2E[n,nn]'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.g(\"map_sumXinE2E\").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of our starting values were set 'as if' the entire tree was Leontief, it is worth noting that the default values for substitutions of elasticity/transformation are 1, e.g. for $\\sigma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n\n",
       "C0_EH          0.0001\n",
       "basetech_ER    0.0001\n",
       "C_ER_1         0.0001\n",
       "basetech_EL    0.0001\n",
       "ID_2           0.0001\n",
       "Name: sigma, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.default_var_series(\"sigma\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second requirement(s) are the properties `endo_groups` and `exo_groups`. These collect the variables in groups and specify which of these subgroups are part of the two upper groups of endogenous and exogenous variables/parameters respectively. The choice of whether a variable should be endogenous or exogenous changes e.g. depending on whether the model is about to be solved for calibration purposes or not.\n",
    "In the basic case (not calibration mode), the endogenous variables are split into multiple groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Abatement_g_ID_prices_alwaysendo', 'Abatement_g_emissions_alwaysendo', 'Abatement_g_ID_quants_alwaysendo', 'Abatement_g_EOP_prices_alwaysendo', 'Abatement_g_prices_endogenouswithEOP', 'Abatement_g_EOP_quants_alwaysendo', 'Abatement_g_emissions_endoinEOP', 'Abatement_g_ID_quants_exoincalib', 'Abatement_g_EOP_quants_exoincalib'])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.endo_groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which themselves include the actual variables. Here we print the values of prices with taxes in the endovars group (the first 5 only). This uses the method *.var_endo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.initialize_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-097279e16a0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_endo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"qD\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\gmspython.py\u001b[0m in \u001b[0;36mvar_endo\u001b[1;34m(self, symbol, db)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;34m\"\"\" Return the variable in 'symbol', sliced according to the union of all endogenous groups.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_custom_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendo_groups\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\gmspython.py\u001b[0m in \u001b[0;36mvar_custom_group\u001b[1;34m(self, symbol, group, db)\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0msname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrctree_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgms_aux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReadCondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0madd_global_settings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkwargs_ns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkwargs_vals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs_oth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36mrctree_pd\u001b[1;34m(self, c)\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[1;34m\"\"\" returns the pandas representation of the variable subsetted according to sets in the conditions tree.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgpy_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_ss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36md_pd\u001b[1;34m(self, kv)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgpy_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgpy_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36mpoint_pd\u001b[1;34m(self, vi)\u001b[0m\n\u001b[0;32m    158\u001b[0m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36md_pd\u001b[1;34m(self, kv)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgpy_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgpy_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36mpoint_pd\u001b[1;34m(self, vi)\u001b[0m\n\u001b[0;32m    158\u001b[0m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36md_pd\u001b[1;34m(self, kv)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgpy_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate_k2pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36mtranslate_k2pd\u001b[1;34m(self, l, k)\u001b[0m\n\u001b[0;32m    167\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'not'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'not'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary ~: 'NoneType'"
     ]
    }
   ],
   "source": [
    "m.var_endo(\"qD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And next we print the exogenous prices with taxes by doing the same thing, but for exogenous groups instead. This is found in the var_exo method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to specify the *add_blocks* method. This is the method that writes blocks of equations to the model. In our case, we write a different block of equations for each tree.\n",
    "For example, a set of equations are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.eqtext(list(m.ns_local)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, the model we have in mind here has the following main settings (where a \\$ denotes a condition):\n",
    "* Endogenous variables: $PwThat\\$(int)$, $PbT\\$(out)$, $qD\\$(wT)$. (Recall that the subset wT is the union of intermediate goods and inputs)\n",
    "* Exogenous variables: $PwThat\\$(inp)$, $qS\\$(out)$. \n",
    "* Equations: For the CES nest we have the following two equations:\n",
    "    $$\\begin{align}\n",
    "        q_j =& \\mu_j\\left(\\dfrac{p_j}{p_i}\\right)^{-\\sigma}q_i, \\tag{CES-1}\\\\\n",
    "        p_iq_i =& \\sum_j q_jp_j \\tag{CES-2}\n",
    "    \\end{align}$$\n",
    "    (CES-1) is the CES demand function that has to hold for all *branches* ($q_j$) where $q_i$ is the relevant knot in the nesting tree. (CES-2) is a zero-profit condition that has to hold for production functions with constant returns to scale (alternatively, we can use a price index). This has to hold for every *knot* where $j$ sums over the relevant branches. A similar thing has to hold for the CET tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Running the model**\n",
    "Running the model, including the invoking the methods and properties described in the previous section, we simply run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2t(x):\n",
    "\treturn list(x.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'qD': {\"and\":[{\"or\":[m.g('EOP_int'), m.g(\"EOP_inp\")]}]}}\n",
    "m.g(\"qD\").d_pd(d2t(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'qS': {\"and\":[m.g('ID_out')]}}\n",
    "m.g(\"qS\").d_pd(d2t(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C0_EH', 'C0_EL', 'C0_ER', 'C_EH_1', 'C_EH_2', 'C_EH_3', 'C_EL_1',\n",
       "       'C_EL_2', 'C_EL_3', 'C_EL_4',\n",
       "       ...\n",
       "       'basetech_EL_inp4', 'basetech_EL_inp5', 'basetech_EL_oil',\n",
       "       'basetech_ER', 'basetech_ER_K', 'basetech_ER_electricity',\n",
       "       'basetech_ER_inp3', 'basetech_ER_inp4', 'basetech_ER_inp5',\n",
       "       'basetech_ER_oil'],\n",
       "      dtype='object', name='n', length=118)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get(\"qD\").index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DB2Gams_l2.gams_model_py at 0x23e65baf748>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n\n",
       "C_EL_1     5.0\n",
       "C_EL_2     2.5\n",
       "C_EL_3     2.5\n",
       "C_EH_1    15.0\n",
       "C_EL_4    17.5\n",
       "C_EL_5     3.0\n",
       "C_EH_2     3.0\n",
       "C_ER_1     3.0\n",
       "C_EH_3     5.0\n",
       "C_ER_2     4.0\n",
       "C0_EL     69.5\n",
       "C0_EH     77.0\n",
       "C0_ER     93.0\n",
       "Name: qD, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get(\"qD\")[m.get(\"ID_endovars_exoincalib_C\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = {\"and\":[db['n_prod'], db[\"d_tauD\"], {\"not\":db[\"d_tauS\"]}]}\n",
    "# c = {'qD': {\"and\":[{\"or\":[m.g('ID_int'), m.g(\"ID_inp\")]}, {\"not\":{\"or\":[m.g(\"ID_endovars_exoincalib_C\"), m.g(\"ID_endovars_exoincalib_E\")]}}]  }}\n",
    "# m.g(\"qD\").rctree_pd(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C_EL_1', 'C_EL_2', 'C_EL_3', 'C_EH_1', 'C_EL_4', 'C_EL_5', 'C_EH_2',\n",
       "       'C_ER_1', 'C_EH_3', 'C_ER_2', 'C0_EL', 'C0_EH', 'C0_ER'],\n",
       "      dtype='object', name='n')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get(\"ID_endovars_exoincalib_C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n\n",
       "C0_EH                      77.000000\n",
       "C0_EL                      69.500000\n",
       "C0_ER                      93.000000\n",
       "C_EH_1                     15.000000\n",
       "C_EH_2                      3.000000\n",
       "                             ...    \n",
       "basetech_ER_electricity    16.333333\n",
       "basetech_ER_inp3           16.333333\n",
       "basetech_ER_inp4           16.333333\n",
       "basetech_ER_inp5           16.333333\n",
       "basetech_ER_oil            16.333333\n",
       "Name: qD, Length: 118, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.var_endo(\"qD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'qD',\n",
       "  'conditions': {'and': [{'or': [<DataBase.gpy_symbol at 0x260565ce9c8>,\n",
       "      <DataBase.gpy_symbol at 0x260565ce988>]},\n",
       "    {'not': [{'or': [<DataBase.gpy_symbol at 0x260564ef808>,\n",
       "        <DataBase.gpy_symbol at 0x260564ef6c8>]}]}]}}]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model.groups[\"Abatement_g_ID_quants_alwaysendo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group(group,db):\n",
    "\tout = ''\n",
    "\tfor g in group:\n",
    "\t\tprint(out)\n",
    "\t\tprint(g)\n",
    "\t\tif isinstance(g,dict):\n",
    "\t\t\tout += d2g(g,db)\n",
    "\t\telif isinstance(g,list):\n",
    "\t\t\tout += l2g(g,db=db)\n",
    "\t\telif isinstance(g,str):\n",
    "\t\t\tout += g+'\\n'\n",
    "\treturn out\n",
    "\n",
    "def d2g(d,db):\n",
    "\treturn db[d['name']].write(conditions=rc_d2g(d,db))+' \"{text}\"\\n'.format(text=df('text','',d))\n",
    "\n",
    "def rc_d2g(d,db):\n",
    "\tif 'conditions' not in d:\n",
    "\t\tprint(\"first\")\n",
    "\t\treturn None\n",
    "\telif isinstance(d['conditions'],str):\n",
    "\t\tprint(\"second\")\n",
    "\t\treturn d['conditions']\n",
    "\telse:\n",
    "\t\tprint(\"third\")\n",
    "\t\treturn db[d['name']].rctree_gams(d['conditions'])\n",
    "\n",
    "def l2g(g,db=None):\n",
    "\t\"\"\" a list with two elements indicate '+/-' in first element (add or subtract to/from group), and variable in second. If second is dict, this is written as a variable.\"\"\"\n",
    "\tif isinstance(g[1], dict):\n",
    "\t\treturn ''.join([g[0],d2g(g[1],db)])\n",
    "\telse:\n",
    "\t\treturn ''.join(g)+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = m.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = self.groups[\"Abatement_g_ID_quants_alwaysendo\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = d[\"conditions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': [{'or': [<DataBase.gpy_symbol at 0x23e3d868e88>,\n",
       "    <DataBase.gpy_symbol at 0x23e3d868e08>]},\n",
       "  {'not': {'or': [<DataBase.gpy_symbol at 0x23e3d86fe88>,\n",
       "     <DataBase.gpy_symbol at 0x23e3d86fe48>]}}]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym = self.database[\"qD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = d2t(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'or': [<DataBase.gpy_symbol at 0x23e3d868e88>,\n",
       "   <DataBase.gpy_symbol at 0x23e3d868e08>]},\n",
       " {'not': {'or': [<DataBase.gpy_symbol at 0x23e3d86fe88>,\n",
       "    <DataBase.gpy_symbol at 0x23e3d86fe48>]}}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not': {'or': [<DataBase.gpy_symbol at 0x23e3d86fe88>,\n",
       "   <DataBase.gpy_symbol at 0x23e3d86fe48>]}}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>]}}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'((ID_int[n] or ID_inp[n]) and not (ID_endovars_exoincalib_C[n] or ID_endovars_exoincalib_E[n]))'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sym.rctree_gams(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third\n",
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>]}}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'((ID_int[n] or ID_inp[n]) and not (ID_endovars_exoincalib_C[n] or ID_endovars_exoincalib_E[n]))'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_d2g(d, self.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'name': 'qD', 'conditions': {'and': [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>]}}]}}\n",
      "third\n",
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>]}}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-41f293e14945>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0madd_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Abatement_g_ID_quants_alwaysendo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-124-a043ca0c49f8>\u001b[0m in \u001b[0;36madd_group\u001b[1;34m(group, db)\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0md2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-a043ca0c49f8>\u001b[0m in \u001b[0;36md2g\u001b[1;34m(d, db)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0md2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrc_d2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' \"{text}\"\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrc_d2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "add_group(self.groups[\"Abatement_g_ID_quants_alwaysendo\"], self.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = m.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = {'qS': {\"and\":[m.g('ID_out')]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-92ad4764737f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"qS\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrctree_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\GPM_v05\\py_main\\DataBase.py\u001b[0m in \u001b[0;36mrctree_pd\u001b[1;34m(self, c)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;34m\"\"\" returns the pandas representation of the variable subsetted according to sets in the conditions tree.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgpy_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_ss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "m.g(\"qS\").rctree_pd(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qD',\n",
       " {'and': [{'or': [<DataBase.gpy_symbol at 0x270c68c1348>,\n",
       "     <DataBase.gpy_symbol at 0x270c68c15c8>]},\n",
       "   {'not': [{'or': [<DataBase.gpy_symbol at 0x270c69c6908>,\n",
       "       <DataBase.gpy_symbol at 0x270c69c68c8>]}]}]})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = {'qD': {\"and\":[{\"or\":[m.g('ID_int'), m.g(\"ID_inp\")]}, {\"not\":[{\"or\":[m.g(\"ID_endovars_exoincalib_C\"), m.g(\"ID_endovars_exoincalib_E\")]}]}]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = d2t(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qD',\n",
       " {'and': [{'or': [<DataBase.gpy_symbol at 0x270c68c1348>,\n",
       "     <DataBase.gpy_symbol at 0x270c68c15c8>]},\n",
       "   {'not': [{'or': [<DataBase.gpy_symbol at 0x270c69c6908>,\n",
       "       <DataBase.gpy_symbol at 0x270c69c68c8>]}]}]})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vi for vi in kv[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.g(\"qD\").point_pd(vi) for vi in kv[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.g(\"qD\").d_pd(d2t(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'name': 'qD', 'conditions': {'and': [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>]}}]}}\n",
      "third\n",
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>]}}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-41f293e14945>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0madd_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Abatement_g_ID_quants_alwaysendo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-124-a043ca0c49f8>\u001b[0m in \u001b[0;36madd_group\u001b[1;34m(group, db)\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0md2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-a043ca0c49f8>\u001b[0m in \u001b[0;36md2g\u001b[1;34m(d, db)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0md2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrc_d2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' \"{text}\"\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrc_d2g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "add_group(self.groups[\"Abatement_g_ID_quants_alwaysendo\"], self.database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n\n",
       "C0_EH                   77.0\n",
       "C0_EL                   69.5\n",
       "C0_ER                   93.0\n",
       "C_EH_1                  15.0\n",
       "C_EH_2                   3.0\n",
       "C_EH_3                   5.0\n",
       "C_EL_1                   5.0\n",
       "C_EL_2                   2.5\n",
       "C_EL_3                   2.5\n",
       "C_EL_4                  17.5\n",
       "C_EL_5                   3.0\n",
       "C_ER_1                   3.0\n",
       "C_ER_2                   4.0\n",
       "EH                     100.0\n",
       "EL                     100.0\n",
       "EOP_t1                 150.0\n",
       "EOP_t1_K               750.0\n",
       "EOP_t2                 250.0\n",
       "EOP_t2_K              1000.0\n",
       "EOP_t2_electricity     250.0\n",
       "EOP_t3                 100.0\n",
       "EOP_t3_K               370.0\n",
       "EOP_t3_inp3             50.0\n",
       "EOP_t3_inp4             20.0\n",
       "EOP_t3_inp5             30.0\n",
       "EOP_t4                 150.0\n",
       "EOP_t4_K               600.0\n",
       "EOP_t4_inp4            150.0\n",
       "EOP_t5                 150.0\n",
       "EOP_t5_K               450.0\n",
       "Name: qD, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.var_endo(\"qD\").head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abatement_g_ID_prices_alwaysendo\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>])\n",
      "Abatement_g_emissions_alwaysendo\n",
      "Abatement_g_ID_quants_alwaysendo\n",
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>]}}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D868E88>, <DataBase.gpy_symbol object at 0x0000023E3D868E08>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>])\n",
      "Abatement_g_EOP_prices_alwaysendo\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE08>, <DataBase.gpy_symbol object at 0x0000023E3D849AC8>])\n",
      "Abatement_g_prices_endogenouswithEOP\n",
      "Abatement_g_EOP_quants_alwaysendo\n",
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000023E3D86FE08>, <DataBase.gpy_symbol object at 0x0000023E3D849AC8>]}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE08>, <DataBase.gpy_symbol object at 0x0000023E3D849AC8>])\n",
      "Abatement_g_emissions_endoinEOP\n",
      "Abatement_g_ID_quants_exoincalib\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D86FE88>, <DataBase.gpy_symbol object at 0x0000023E3D86FE48>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000023E3D872208>, <DataBase.gpy_symbol object at 0x0000023E3D872248>])\n",
      "Abatement_g_EOP_quants_exoincalib\n",
      "Abatement_g_ID_params_alwaysexo\n",
      "kv:\n",
      "('and', [<DataBase.gpy_symbol object at 0x0000023E3D868F88>, {'not': <DataBase.gpy_symbol object at 0x0000023E3D86FF88>}])\n",
      "Abatement_g_ID_prices_alwaysexo\n",
      "Abatement_g_prices_alwaysexo\n",
      "Abatement_g_ID_quants_alwaysexo\n",
      "kv:\n",
      "('and', [<DataBase.gpy_symbol object at 0x0000023E3D868E48>])\n",
      "Abatement_g_emissions_alwaysexo\n",
      "Abatement_g_EOP_params_alwaysexo\n",
      "Abatement_g_EOP_prices_alwaysexo\n",
      "Abatement_g_ID_params_endoincalib\n",
      "Abatement_g_EOP_params_endoincalib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$GROUP Abatement_g_ID_prices_alwaysendo\\nPwThat[n]$((ID_int[n] or ID_inp[n])) \"\"\\nPbT[n]$(ID_out[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_emissions_alwaysendo\\nM0[n]$(M_subset[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_ID_quants_alwaysendo\\nqD[n]$(((ID_int[n] or ID_inp[n]) and not (ID_endovars_exoincalib_C[n] or ID_endovars_exoincalib_E[n]))) \"\"\\n;\\n\\n$GROUP Abatement_g_EOP_prices_alwaysendo\\nPwThat[n]$((EOP_int[n] or EOP_inp[n])) \"\"\\nPbT[n]$(EOP_out[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_prices_endogenouswithEOP\\npMhat[n]$(M_subset[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_EOP_quants_alwaysendo\\nqD[n]$(((EOP_int[n] or EOP_inp[n]))) \"\"\\nqS[n]$(EOP_out[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_emissions_endoinEOP\\nM[n]$(M_subset[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_ID_quants_exoincalib\\nqD[n]$((ID_endovars_exoincalib_C[n] or ID_endovars_exoincalib_E[n])) \"\"\\nqsumU[n]$(ID_sumUaggs[n]) \"\"\\nqsumX[n]$((sumXinEaggs[n] or sumXrestaggs[n])) \"\"\\n;\\n\\n$GROUP Abatement_g_EOP_quants_exoincalib\\nqsumU[n]$(EOP_sumUaggs[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_ID_params_alwaysexo\\nsigma[n]$((ID_kno_inp[n] and not ID_tech_endoincalib_sigma[n])) \"\"\\nmu[n,nn]$(ID_params_alwaysexo_mu[n,nn]) \"\"\\neta[n]$(ID_kno_out[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_ID_prices_alwaysexo\\nPwT[n]$(ID_inp[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_prices_alwaysexo\\npM[n]$(M_subset[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_ID_quants_alwaysexo\\nqS[n]$((ID_out[n])) \"\"\\n;\\n\\n$GROUP Abatement_g_emissions_alwaysexo\\nphi[n,nn]$(map_M2X[n,nn]) \"\"\\n;\\n\\n$GROUP Abatement_g_EOP_params_alwaysexo\\ntheta[n]$(EOP_out[n]) \"\"\\nsigma[n]$(EOP_kno_inp[n]) \"\"\\nmu[n,nn]$(EOP_params_alwaysexo_mu[n,nn]) \"\"\\neta[n]$(EOP_kno_out[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_EOP_prices_alwaysexo\\nPwT[n]$(EOP_inp[n]) \"\"\\n;\\n\\n$GROUP Abatement_g_ID_params_endoincalib\\nsigma[n]$(ID_tech_endoincalib_sigma[n]) \"\"\\nmu[n,nn]$(ID_tech_endoincalib_mu[n,nn]) \"\"\\n;\\n\\n$GROUP Abatement_g_EOP_params_endoincalib\\nmuG[n]$(EOP_out[n]) \"\"\\nsigmaG[n]$(EOP_out[n]) \"\"\\n;\\n\\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model.write_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'qD',\n",
       "  'conditions': {'and': [{'or': [<DataBase.gpy_symbol at 0x297b70ead48>,\n",
       "      <DataBase.gpy_symbol at 0x297b70ead88>]},\n",
       "    {'not': [{'or': [<DataBase.gpy_symbol at 0x297b7162f48>,\n",
       "        <DataBase.gpy_symbol at 0x297b7162fc8>]}]}]}}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model.groups[\"Abatement_g_ID_quants_alwaysendo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abatement_g_ID_prices_alwaysendo\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000026874A53188>, <DataBase.gpy_symbol object at 0x0000026874A53108>])\n",
      "Abatement_g_emissions_alwaysendo\n",
      "Abatement_g_ID_quants_alwaysendo\n",
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000026874A53188>, <DataBase.gpy_symbol object at 0x0000026874A53108>]}, {'not': {'or': [<DataBase.gpy_symbol object at 0x0000026874A5E308>, <DataBase.gpy_symbol object at 0x0000026874A5E1C8>]}}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000026874A53188>, <DataBase.gpy_symbol object at 0x0000026874A53108>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000026874A5E308>, <DataBase.gpy_symbol object at 0x0000026874A5E1C8>])\n",
      "Abatement_g_EOP_prices_alwaysendo\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000026874A5E088>, <DataBase.gpy_symbol object at 0x0000026874A5E2C8>])\n",
      "Abatement_g_prices_endogenouswithEOP\n",
      "Abatement_g_EOP_quants_alwaysendo\n",
      "kv:\n",
      "('and', [{'or': [<DataBase.gpy_symbol object at 0x0000026874A5E088>, <DataBase.gpy_symbol object at 0x0000026874A5E2C8>]}])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000026874A5E088>, <DataBase.gpy_symbol object at 0x0000026874A5E2C8>])\n",
      "Abatement_g_emissions_endoinEOP\n",
      "Abatement_g_ID_quants_exoincalib\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000026874A5E308>, <DataBase.gpy_symbol object at 0x0000026874A5E1C8>])\n",
      "kv:\n",
      "('or', [<DataBase.gpy_symbol object at 0x0000026874A5E688>, <DataBase.gpy_symbol object at 0x0000026874A5E6C8>])\n",
      "Abatement_g_EOP_quants_exoincalib\n",
      "Abatement_g_ID_params_alwaysexo\n",
      "kv:\n",
      "('and', [<DataBase.gpy_symbol object at 0x0000026874A53288>, {'not': <DataBase.gpy_symbol object at 0x0000026874A5E448>}])\n",
      "Abatement_g_ID_prices_alwaysexo\n",
      "Abatement_g_prices_alwaysexo\n",
      "Abatement_g_ID_quants_alwaysexo\n",
      "kv:\n",
      "('and', [<DataBase.gpy_symbol object at 0x0000026874A53148>])\n",
      "Abatement_g_emissions_alwaysexo\n",
      "Abatement_g_EOP_params_alwaysexo\n",
      "Abatement_g_EOP_prices_alwaysexo\n",
      "Abatement_g_ID_params_endoincalib\n",
      "Abatement_g_EOP_params_endoincalib\n"
     ]
    }
   ],
   "source": [
    "m.write_and_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether the model was successfully solved, we check the modelstat (16.0 means solved correctly, 5.0 means not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'execute_name': 'CollectAndRun.gms',\n",
       " 'name': 'gmodel',\n",
       " 'settings': <DB2Gams_l2.gams_settings at 0x26874767408>,\n",
       " 'export_settings': {'dropattrs': ['settings', 'opt', 'job'],\n",
       "  'pklattrs': {'settings': 'gams_settings'},\n",
       "  'opt': 'conopt4.opt'},\n",
       " 'opt': <gams.options.GamsOptions at 0x26874791848>,\n",
       " 'opt_file': 'conopt4.opt',\n",
       " 'import_settings': {},\n",
       " 'job': <gams.execution.GamsJob at 0x26873084f48>,\n",
       " 'out_db': <DataBase.GPM_database at 0x26874a8bc88>,\n",
       " 'modelstat': 16.0,\n",
       " 'solvestat': 1.0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model_instances[\"baseline\"].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run in the ID state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.setstate(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ID'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.initialize_variables(**{\"check_variables\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.write_and_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model_instances[\"baseline\"].modelstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.setstate(\"EOP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.write_and_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model_instances[\"baseline\"].modelstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not run when all sigmas are not set to be Leontief, i.e. when they use their default value of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to solve the model while instead of the default value of substitution and transformation elasticities of 0.1, we set them equal to zero (in practice not exactly, but very close).\n",
    "Since the starting values have been set under the assumption of Leontief nests, this will help the solver find an initial solution.\n",
    "Since EOP is not consistent with Leontief, these elasticities specifically must not be zero. To make sure we will always find a solution, we choose a high number, e.g. 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! The modelstat was 16.0\n"
     ]
    }
   ],
   "source": [
    "# m.model.settings.databases[\"Abatement_0\"][\"sigma\"].vals.loc[:] = 0.0001\n",
    "# m.model.settings.databases[\"Abatement_0\"][\"eta\"].vals.loc[:] = -0.0001\n",
    "#m.get(\"sigma\")[:] = 0.0001\n",
    "# m.get(\"sigma\")[m.get(\"EOP_C_subset\")] = 2\n",
    "#m.get(\"eta\")[:] = -0.0001\n",
    "# m.get(\"eta\")[m.get(\"eta\").index.str.startswith(\"EOP\")] = -2\n",
    "\n",
    "#m.model.settings.databases[\"Abatement\"][\"sigma\"].vals[condition] = 0.2\n",
    "#m.write_and_run(options_run={'output':sys.stdout})\n",
    "m.write_and_run()\n",
    "if m.model_instances[\"baseline\"].modelstat == 16.0:\n",
    "    print(\"\\nSuccess! The modelstat was 16.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model by pickling it, using the export method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\zgr679\\\\Documents\\\\GitHub\\\\GPM_v05\\\\examples\\\\Abatement\\\\Data\\\\..\\\\gamsmodels\\\\Main\\\\gmspython_Abatement'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is calibrated in the next jupyter file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
